@inproceedings{2022malkin,
    title={Trajectory balance: Improved credit assignment in {GF}lowNets},
    author={Nikolay Malkin and Moksh Jain and Emmanuel Bengio and Chen Sun and Yoshua Bengio},
    booktitle={Advances in Neural Information Processing Systems},
    editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
    year={2022},
    url={https://openreview.net/forum?id=5btWTw1vcw1}
}

@misc{2023madan,
    title={Learning {GF}lowNets from partial episodes for improved convergence and stability},
    author={Kanika Madan and Jarrid Rector-Brooks and Maksym Korablyov and Emmanuel Bengio and Moksh Jain and Andrei Cristian Nica and Tom Bosc and Yoshua Bengio and Nikolay Malkin},
    year={2023},
    url={https://openreview.net/forum?id=UYS38ssi1M}
}

@inproceedings{2023ashman,
    title={Causal Reasoning in the Presence of Latent Confounders via Neural {ADMG} Learning},
    author={Matthew Ashman and Chao Ma and Agrin Hilmkil and Joel Jennings and Cheng Zhang},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=dcN0CaXQhT}
}

@online{2024trainfactguy,
    author={Train Fact Guy},
    title={Everything Wrong with the Trains in Horror Express},
    date={2024-10-18},
    url={https://www.youtube.com/watch?v=C3C76Gr9ydo},
    urldate={2025-10-19},
    organization={Train of Thought}
}

@article{2025duong,
    title={Reinforcement Learning for Causal Discovery without Acyclicity Constraints},
    author={Bao Duong and Hung Le and Biwei Huang and Thin Nguyen},
    journal={Transactions on Machine Learning Research},
    issn={2835-8856},
    year={2025},
    url={https://openreview.net/forum?id=sNzBi8rZTy},
    note={}
}

@article{2022zanga,
    title = {A Survey on Causal Discovery: Theory and Practice},
    journal = {International Journal of Approximate Reasoning},
    volume = {151},
    pages = {101-129},
    year = {2022},
    issn = {0888-613X},
    doi = {https://doi.org/10.1016/j.ijar.2022.09.004},
    url = {https://www.sciencedirect.com/science/article/pii/S0888613X22001402},
    author = {Alessio Zanga and Elif Ozkirimli and Fabio Stella},
    keywords = {Causality, Causal models, Causal discovery, Structural learning},
    abstract = {Understanding the laws that govern a phenomenon is the core of scientific progress. This is especially true when the goal is to model the interplay between different aspects in a causal fashion. Indeed, causal inference itself is specifically designed to quantify the underlying relationships that connect a cause to its effect. Causal discovery is a branch of the broader field of causality in which causal graphs are recovered from data (whenever possible), enabling the identification and estimation of causal effects. In this paper, we explore recent advancements in causal discovery in a unified manner, provide a consistent overview of existing algorithms developed under different settings, report useful tools and data, present real-world applications to understand why and how these methods can be fruitfully exploited.}
}

@article{2006kesteloot,
  title     = "Dynamics of cardiovascular and all-cause mortality in Western
               and Eastern Europe between 1970 and 2000",
  author    = "Kesteloot, Hugo and Sans, Susana and Kromhout, Daan",
  abstract  = "AIMS: Important changes in cardiovascular and all-cause
               mortality rates are occurring in Western and Eastern Europe,
               each with their own dynamics. Differences in trends will be
               analysed and possible causes are discussed. METHODS AND RESULTS:
               Mortality data for cardiovascular and all-cause mortality rates
               from different countries were obtained from WHO and were
               analysed for the period 1970-2000. The annual changes in
               cause-specific mortality rates were calculated using linear and
               polynomial regression models. Mortality rates declined almost
               linearly for ischaemic heart disease, stroke, and total
               cardiovascular diseases between 1970 and 2000 in Western Europe.
               In both men and women, the decline for these diseases varied
               between 50 and 65\% or approximately 2\%/year in this period. In
               contrast, in Eastern Europe cardiovascular mortality rates
               reached a maximum in the period 1990-94, followed by a decline
               of approximately 3\%/year in Poland, 2\%/year in Hungary, and
               5\%/year in the Baltic states. The changes in cardiovascular
               mortality rates were reflected in all-cause mortality rates in
               both Western and Eastern Europe. CONCLUSION: Over the past 30
               years, mortality rates in cardiovascular diseases increased or
               decreased very rapidly. The causes are complex but changes in
               diet appear to play a major role. The more recent declines in
               Western Europe also reflect improvements in modern
               cardiovascular treatment.",
  journal   = "Eur. Heart J.",
  publisher = "Oxford University Press (OUP)",
  volume    =  27,
  number    =  1,
  pages     = "107--113",
  month     =  jan,
  year      =  2006,
  language  = "en"
}

@InProceedings{2016pena,
    title = 	 {Learning Acyclic Directed Mixed Graphs from Observations and Interventions},
    author = 	 {Peña, Jose M.},
    booktitle = 	 {Proceedings of the Eighth International Conference on Probabilistic Graphical Models},
    pages = 	 {392--402},
    year = 	 {2016},
    editor = 	 {Antonucci, Alessandro and Corani, Giorgio and Campos, Cassio Polpo},
    volume = 	 {52},
    series = 	 {Proceedings of Machine Learning Research},
    address = 	 {Lugano, Switzerland},
    month = 	 {06--09 Sep},
    publisher =    {PMLR},
    pdf = 	 {http://proceedings.mlr.press/v52/pena16.pdf},
    url = 	 {https://proceedings.mlr.press/v52/pena16.html},
    abstract = 	 {We introduce a new family of mixed graphical models that consists of graphs with possibly directed, undirected and bidirected edges but without directed cycles. Moreover, there can be up to three edges between any pair of nodes. The new family includes Richardson’s acyclic directed mixed graphs, as well as Andersson-Madigan-Perlman chain graphs. These features imply that no family of mixed graphical models that we know of subsumes the new models. We also provide a causal interpretation of the new models as systems of structural equations with correlated errors. Finally, we describe an exact algorithm for learning the new models from observational and interventional data via answer set programming.}
}

@article{1974akaike,
    author={Akaike, H.},
    journal={IEEE Transactions on Automatic Control},
    title={A new look at the statistical model identification},
    year={1974},
    volume={19},
    number={6},
    pages={716-723},
    keywords={Testing;Maximum likelihood estimation;Time series analysis;Estimation theory;Linear systems;Roundoff errors;History;Stochastic processes;Sampling methods;Art},
    doi={10.1109/TAC.1974.1100705}
}

@article{1978schwarz,
    ISSN = {00905364, 21688966},
    URL = {http://www.jstor.org/stable/2958889},
    abstract = {The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.},
    author = {Gideon Schwarz},
    journal = {The Annals of Statistics},
    number = {2},
    pages = {461--464},
    publisher = {Institute of Mathematical Statistics},
    title = {Estimating the Dimension of a Model},
    urldate = {2025-11-24},
    volume = {6},
    year = {1978}
}

@incollection{1994geiger,
    title = {Learning Gaussian Networks},
    editor = {Ramon Lopez {de Mantaras} and David Poole},
    booktitle = {Uncertainty in Artificial Intelligence},
    publisher = {Morgan Kaufmann},
    address = {San Francisco (CA)},
    pages = {235-243},
    year = {1994},
    isbn = {978-1-55860-332-5},
    doi = {https://doi.org/10.1016/B978-1-55860-332-5.50035-3},
    url = {https://www.sciencedirect.com/science/article/pii/B9781558603325500353},
    author = {Dan Geiger and David Heckerman},
    abstract = {We describe scoring metrics for learning Bayesian networks from a combination of user knowledge and statistical data. Previous work has concentrated on metrics for domains containing only discrete variables, under the assumption that data represents a multinomial sample. In this paper, we extend this work, developing scoring metrics for domains containing only continuous variables under the assumption that continuous data is sampled from a multivariate normal distribution. Our work extends traditional statistical approaches for identifying vanishing regression coefficients in that we identify two important assumptions, called event equivalence and parameter modularity, that when combined allow the construction of prior distributions for multivariate normal parameters from a single prior Bayesian network specified by a user.}
}

@inproceedings{2018zheng,
    author = {Zheng, Xun and Aragam, Bryon and Ravikumar, Pradeep K and Xing, Eric P},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {DAGs with NO TEARS: Continuous Optimization for Structure Learning},
    url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/e347c51419ffb23ca3fd5050202f9c3d-Paper.pdf},
    volume = {31},
    year = {2018}
}


@article{2019nauta,
    author = {Nauta, Meike and Bucur, Doina and Seifert, Christin},
    title = {Causal Discovery with Attention-Based Convolutional Neural Networks},
    journal = {Machine Learning and Knowledge Extraction},
    volume = {1},
    year = {2019},
    number = {1},
    pages = {312--340},
    url = {https://www.mdpi.com/2504-4990/1/1/19},
    issn = {2504-4990},
    abstract = {Having insight into the causal associations in a complex system facilitates decision making, e.g., for medical treatments, urban infrastructure improvements or financial investments. The amount of observational data grows, which enables the discovery of causal relationships between variables from observation of their behaviour in time. Existing methods for causal discovery from time series data do not yet exploit the representational power of deep learning. We therefore present the Temporal Causal Discovery Framework (TCDF), a deep learning framework that learns a causal graph structure by discovering causal relationships in observational time series data. TCDF uses attention-based convolutional neural networks combined with a causal validation step. By interpreting the internal parameters of the convolutional networks, TCDF can also discover the time delay between a cause and the occurrence of its effect. Our framework learns temporal causal graphs, which can include confounders and instantaneous effects. Experiments on financial and neuroscientific benchmarks show state-of-the-art performance of TCDF on discovering causal relationships in continuous time series data. Furthermore, we show that TCDF can circumstantially discover the presence of hidden confounders. Our broadly applicable framework can be used to gain novel insights into the causal dependencies in a complex system, which is important for reliable predictions, knowledge discovery and data-driven decision making.},
    doi = {10.3390/make1010019}
}


@article{2020wang,
  title={Causal Discovery from Incomplete Data: A Deep Learning Approach},
  author={Yuhao Wang and Vlado Menkovski and Hao Wang and Xin Du and Mykola Pechenizkiy},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.05343},
  url={https://api.semanticscholar.org/CorpusID:210701213}
}

@book{2009pearl,
    author = {Pearl, Judea},
    title = {Causality: Models, Reasoning and Inference},
    year = {2009},
    isbn = {052189560X},
    publisher = {Cambridge University Press},
    address = {USA},
    edition = {2nd},
    abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 3,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.}
}


@InProceedings{2023ramsey,
  title = 	 {Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for Tetrad Causal Search},
  author =       {Ramsey, Joseph and Andrews, Bryan},
  booktitle = 	 {Proceedings of the 2023 Causal Analysis Workshop Series},
  pages = 	 {40--51},
  year = 	 {2023},
  editor = 	 {Kummerfeld, Erich and Ma, Sisi and Rawls, Eric and Andrews, Bryan},
  volume = 	 {223},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {Aug},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v223/ramsey23a/ramsey23a.pdf},
  url = 	 {https://proceedings.mlr.press/v223/ramsey23a.html},
  abstract = 	 {We give novel Python and R interfaces for the (Java) Tetrad project for causal modeling, search, and estimation. The Tetrad project is a mainstay in the literature, having been under consistent development for over 30 years. Some of its algorithms are now classics, like PC and FCI; others are recent developments. It is increasingly the case, however, that researchers need to access the underlying Java code from Python or R. Existing methods for doing this are inadequate. We provide new, up-to-date methods using the JPype Python-Java interface and the Reticulate Python-R interface, directly solving these issues. With the addition of some simple tools and the provision of working examples for both Python and R, using JPype and Reticulate to interface Python and R with Tetrad is straightforward and intuitive.}
}

@inproceedings{2018ramseya,
  title={TETRAD - A TOOLBOX FOR CAUSAL DISCOVERY},
  author={Joseph Ramsey and Kun Zhang and Madelyn Glymour and Ruben Sanchez Romero and Biwei Huang and Imm{\'e} and Ebert-Uphoff and Savini M. Samarasinghe and Elizabeth A. Barnes and Clark Glymour},
  booktitle={8th international workshop on climate informatics},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:201054499}
}

@article{1984erdos,
  title={On the evolution of random graphs},
  author={Paul L. Erd\H{o}s and Alfr{\'e}d R{\'e}nyi},
  journal={Transactions of the American Mathematical Society},
  year={1984},
  volume={286},
  pages={257-257},
  url={https://api.semanticscholar.org/CorpusID:6829589}
}

@article{2021raffin,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1--8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@misc{2019hansen,
  author       = {Nikolaus Hansen and Youhei Akimoto and Petr Baudis},
  title        = {{CMA-ES/pycma} on {G}ithub},
  howpublished = {Zenodo, DOI:10.5281/zenodo.2559634},
  month        = feb,
  year         = 2019,
  doi          = {10.5281/zenodo.2559634},
  url          = {https://doi.org/10.5281/zenodo.2559634},
}


@InProceedings{2021bhattacharya,
  title = 	 { Differentiable Causal Discovery Under Unmeasured Confounding },
  author =       {Bhattacharya, Rohit and Nagarajan, Tushar and Malinsky, Daniel and Shpitser, Ilya},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2314--2322},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/bhattacharya21a/bhattacharya21a.pdf},
  url = 	 {https://proceedings.mlr.press/v130/bhattacharya21a.html},
  abstract = 	 { The data drawn from biological, economic, and social systems are often confounded due to the presence of unmeasured variables. Prior work in causal discovery has focused on discrete search procedures for selecting acyclic directed mixed graphs (ADMGs), specifically ancestral ADMGs, that encode ordinary conditional independence constraints among the observed variables of the system. However, confounded systems also exhibit more general equality restrictions that cannot be represented via these graphs, placing a limit on the kinds of structures that can be learned using ancestral ADMGs. In this work, we derive differentiable algebraic constraints that fully characterize the space of ancestral ADMGs, as well as more general classes of ADMGs, arid ADMGs and bow-free ADMGs, that capture all equality restrictions on the observed variables. We use these constraints to cast causal discovery as a continuous optimization problem and design differentiable procedures to find the best fitting ADMG when the data comes from a confounded linear system of equations with correlated errors. We demonstrate the efficacy of our method through simulations and application to a protein expression dataset. Code implementing our methods is open-source and publicly available at https://gitlab.com/rbhatta8/dcd and will be incorporated into the Ananke package. }
}

@article{2005sachs,
    author = {Karen Sachs  and Omar Perez  and Dana Pe'er  and Douglas A. Lauffenburger  and Garry P. Nolan },
    title = {Causal Protein-Signaling Networks Derived from Multiparameter Single-Cell Data},
    journal = {Science},
    volume = {308},
    number = {5721},
    pages = {523-529},
    year = {2005},
    doi = {10.1126/science.1105809},
    URL = {https://www.science.org/doi/abs/10.1126/science.1105809},
    eprint = {https://www.science.org/doi/pdf/10.1126/science.1105809},
    abstract = {Machine learning was applied for the automated derivation of causal influences in cellular signaling networks. This derivation relied on the simultaneous measurement of multiple phosphorylated protein and phospholipid components in thousands of individual primary human immune system cells. Perturbing these cells with molecular interventions drove the ordering of connections between pathway components, wherein Bayesian network computational methods automatically elucidated most of the traditionally reported signaling relationships and predicted novel interpathway network causalities, which we verified experimentally. Reconstruction of network models from physiologically relevant primary single cells might be applied to understanding native-state tissue signaling biology, complex drug actions, and dysfunctional signaling in diseased cells.}
}

@Inbook{2016lagani,
    author="Lagani, Vincenzo
    and Triantafillou, Sofia
    and Ball, Gordon
    and Tegn{\'e}r, Jesper
    and Tsamardinos, Ioannis",
    editor="Geris, Liesbet
    and Gomez-Cabrero, David",
    title="Probabilistic Computational Causal Discovery for Systems Biology",
    bookTitle="Uncertainty in Biology: A Computational Modeling Approach",
    year="2016",
    publisher="Springer International Publishing",
    address="Cham",
    pages="33--73",
    abstract="Discovering the causal mechanismsLagani, Vincenzoof biologicalSamuelsson, OscarsystemsTriantafillou, Sofiais necessary to design new drugsBall, Gordonand therapies. Computational Causal Discovery (CD) is a field that offers the potential to discoverTegn{\'e}r, Jespercausal relations and causal models under certainTsamardinos, Ioannisconditions with a limitedBall, Gordonset of interventions/manipulations. This chapter reviews the basic concepts and principles of CD, the nature of the assumptions to enable it, potential pitfalls in its application, and recent advances and directions. Importantly, several success stories in molecular and systems biology are discussed in detail.",
    isbn="978-3-319-21296-8",
    doi="10.1007/978-3-319-21296-8_3",
    url="https://doi.org/10.1007/978-3-319-21296-8_3"
}

@article{2019runge,
    author={Runge, Jakob
    and Bathiany, Sebastian
    and Bollt, Erik
    and Camps-Valls, Gustau
    and Coumou, Dim
    and Deyle, Ethan
    and Glymour, Clark
    and Kretschmer, Marlene
    and Mahecha, Miguel D.
    and Mu{\~{n}}oz-Mar{\'i}, Jordi
    and van Nes, Egbert H.
    and Peters, Jonas
    and Quax, Rick
    and Reichstein, Markus
    and Scheffer, Marten
    and Sch{\"o}lkopf, Bernhard
    and Spirtes, Peter
    and Sugihara, George
    and Sun, Jie
    and Zhang, Kun
    and Zscheischler, Jakob},
    title={Inferring causation from time series in Earth system sciences},
    journal={Nature Communications},
    year={2019},
    month={Jun},
    day={14},
    volume={10},
    number={1},
    pages={2553},
    abstract={The heart of the scientific enterprise is a rational effort to understand the causes behind the phenomena we observe. In large-scale complex dynamical systems such as the Earth system, real experiments are rarely feasible. However, a rapidly increasing amount of observational and simulated data opens up the use of novel data-driven causal methods beyond the commonly adopted correlation techniques. Here, we give an overview of causal inference frameworks and identify promising generic application cases common in Earth system sciences and beyond. We discuss challenges and initiate the benchmark platform causeme.netto close the gap between method users and developers.},
    issn={2041-1723},
    doi={10.1038/s41467-019-10105-3},
    url={https://doi.org/10.1038/s41467-019-10105-3}
}

@article{2022sanchez,
  title={Causal machine learning for healthcare and precision medicine},
  author={Sanchez, Pedro and Voisey, Jeremy P and Xia, Tian and Watson, Hannah I and O’Neil, Alison Q and Tsaftaris, Sotirios A},
  journal={Royal Society Open Science},
  volume={9},
  number={8},
  pages={220638},
  year={2022},
  publisher={The Royal Society}
}

@article{2025garg,
  title={Causal Claims in Economics},
  author={Prashant Garg and Thiemo Fetzer},
  journal={ArXiv},
  year={2025},
  volume={abs/2501.06873},
  url={https://api.semanticscholar.org/CorpusID:275470763}
}

@inproceedings{2016ogarrio,
  title = 	 {A Hybrid Causal Search Algorithm for Latent Variable Models},
  author = 	 {Ogarrio, Juan Miguel and Spirtes, Peter and Ramsey, Joe},
  booktitle = 	 {Proceedings of the Eighth International Conference on Probabilistic Graphical Models},
  pages = 	 {368--379},
  year = 	 {2016},
  editor = 	 {Antonucci, Alessandro and Corani, Giorgio and Campos, Cassio Polpo},
  volume = 	 {52},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lugano, Switzerland},
  month = 	 {06--09 Sep},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v52/ogarrio16.pdf},
  url = 	 {https://proceedings.mlr.press/v52/ogarrio16.html},
  abstract = 	 {Existing score-based causal model search algorithms such as GES (and a speeded up version, FGS) are asymptotically correct, fast, and reliable, but make the unrealistic assumption that the true causal graph does not contain any unmeasured confounders. There are several constraint-based causal search algorithms (e.g RFCI, FCI, or FCI+) that are asymptotically correct without assuming that there are no unmeasured confounders, but often perform poorly on small samples. We describe a combined score and constraint-based algorithm, GFCI, that we prove is asymptotically correct. On synthetic data, GFCI is only slightly slower than RFCI but more accurate than FCI, RFCI and FCI+.}
}


@article{2004stolberg,
author = {Stolberg, Harald O. and Norman, Geoffrey and Trop, Isabelle},
title = {Randomized Controlled Trials},
journal = {American Journal of Roentgenology},
volume = {183},
number = {6},
pages = {1539-1544},
year = {2004},
doi = {10.2214/ajr.183.6.01831539},
    note ={PMID: 15547188},
    URL = {https://doi.org/10.2214/ajr.183.6.01831539 },
    eprint = { https://doi.org/10.2214/ajr.183.6.01831539 }
}


@article{2018ramseyb,
  title={FASK with Interventional Knowledge Recovers Edges from the Sachs Model},
  author={Joseph Ramsey and Bryan Andrews},
  journal={ArXiv},
  year={2018},
  volume={abs/1805.03108},
  url={https://api.semanticscholar.org/CorpusID:13686921}
}

@article{2016mooji,
  title={Joint Causal Inference from Multiple Contexts},
  author={Joris M. Mooij and Sara Magliacane and Tom Claassen},
  journal={Journal of Machine Learning Research},
  year={2016},
  volume={21},
  pages={99:1-99:108},
  url={https://api.semanticscholar.org/CorpusID:126017772}
}

@misc{2018haarnoja,
title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
year={2018},
url={https://openreview.net/forum?id=HJjvxl-Cb},
}

@inproceedings{2018henderson,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}


@article{2009drton,
  author  = {Mathias Drton and Michael Eichler and Thomas S. Richardson},
  title   = {Computing Maximum Likelihood Estimates in Recursive Linear Models with Correlated Errors},
  journal = {Journal of Machine Learning Research},
  year    = {2009},
  volume  = {10},
  number  = {81},
  pages   = {2329--2348},
  url     = {http://jmlr.org/papers/v10/drton09a.html}
}

@book{1993spirtes,
	author = {Peter Spirtes and Clark Glymour and Scheines N. and Richard},
	editor = {},
	publisher = {Mit Press: Cambridge},
	title = {Causation, Prediction, and Search},
	year = {1993}
}


@article{2023lee,
  title={Ananke: A python package for causal inference using graphical models},
  author={Lee, Jaron JR and Bhattacharya, Rohit and Nabi, Razieh and Shpitser, Ilya},
  journal={arXiv preprint arXiv:2301.11477},
  year={2023}
}

@misc{2017schulman,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.06347}, 
}

@article{2001hansen,
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  journal={Evolutionary Computation}, 
  title={Completely Derandomized Self-Adaptation in Evolution Strategies}, 
  year={2001},
  volume={9},
  number={2},
  pages={159-195},
  abstract={This paper puts forward two useful methods for self-adaptation of the mutation distribution - the concepts of derandomization and cumulation. Principle shortcomings of the concept of mutative strategy parameter control and two levels of derandomization are reviewed. Basic demands on the self-adaptation of arbitrary (normal) mutation distributions are developed. Applying arbitrary, normal mutation distributions is equiv-alent to applying a general, linear problem encoding. The underlying objective of mutative strategy parameter control is roughly to favor previously selected mutation steps in the future. If this objective is pursued rigor-ously, a completely derandomized self-adaptation scheme results, which adapts arbitrary normal mutation distributions. This scheme, called covariance matrix adaptation (CMA), meets the previously stated demands. It can still be considerably improved by cumulation - utilizing an evolution path rather than single search steps. Simulations on various test functions reveal local and global search properties of the evolution strategy with and without covariance matrix adaptation. Their performances are comparable only on perfectly scaled functions. On badly scaled, non-separable functions usually a speed up factor of several orders of magnitude is ob-served. On moderately mis-scaled functions a speed up factor of three to ten can be expected.},
  keywords={Evolution strategy;self-adaptation;strategy parameter control;step size control;de-randomization;derandomized self-adaptation;covariance matrix adaptation;evolution path;cumulation;cumulative path length control},
  doi={10.1162/106365601750190398},
  ISSN={1063-6560},
  month={June},
}

@misc{2023hansen,
      title={The CMA Evolution Strategy: A Tutorial}, 
      author={Nikolaus Hansen},
      year={2023},
      eprint={1604.00772},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1604.00772}, 
}

@article{2012colombo,
 ISSN = {00905364, 21688966},
 URL = {http://www.jstor.org/stable/41713636},
 abstract = {We consider the problem of learning causal information between random variables in directed acyclic graphs (DAGs) when allowing arbitrarily many latent and selection variables. The FCI (Fast Causal Inference) algorithm has been explicitly designed to infer conditional independence and causal information in such settings. However, FCI is computationally infeasible for large graphs. We therefore propose the new RFCI algorithm, which is much faster than FCI. In some situations the output of RFCI is slightly less informative, in particular with respect to conditional independence information. However, we prove that any causal information in the output of RFCI is correct in the asymptotic limit. We also define a class of graphs on which the outputs of FCI and RFCI are identical. We prove consistency of FCI and RFCI in sparse high-dimensional settings, and demonstrate in simulations that the estimation performances of the algorithms are very similar. All software is implemented in the R-package pcalg.},
 author = {Diego Colombo and Marloes H. Maathuis and Markus Kalisch and Thomas S. Richardson},
 journal = {The Annals of Statistics},
 number = {1},
 pages = {294--321},
 publisher = {Institute of Mathematical Statistics},
 title = {LEARNING HIGH-DIMENSIONAL DIRECTED ACYCLIC GRAPHS WITH LATENT AND SELECTION VARIABLES},
 urldate = {2025-11-30},
 volume = {40},
 year = {2012}
}

@article{2017ramsey,
author={Ramsey, Joseph
and Glymour, Madelyn
and Sanchez-Romero, Ruben
and Glymour, Clark},
title={A million variables and more: the Fast Greedy Equivalence Search algorithm for learning high-dimensional graphical causal models, with an application to functional magnetic resonance images},
journal={International Journal of Data Science and Analytics},
year={2017},
month={Mar},
day={01},
volume={3},
number={2},
pages={121-129},
abstract={We describe two modifications that parallelize and reorganize caching in the well-known Greedy Equivalence Search algorithm for discovering directed acyclic graphs on random variables from sample values. We apply one of these modifications, the Fast Greedy Equivalence Search (fGES) assuming faithfulness, to an i.i.d. sample of 1000 units to recover with high precision and good recall an average degree 2 directed acyclic graph with one million Gaussian variables. We describe a modification of the algorithm to rapidly find the Markov Blanket of any variable in a high dimensional system. Using 51,000 voxels that parcellate an entire human cortex, we apply the fGES algorithm to blood oxygenation level-dependent time series obtained from resting state fMRI.},
issn={2364-4168},
doi={10.1007/s41060-016-0032-z},
url={https://doi.org/10.1007/s41060-016-0032-z}
}

@article{2017nowzohur,
author = {Nowzohour, Christopher and Maathuis, Marloes and Evans, Robin and Bühlmann, Peter},
year = {2017},
month = {01},
pages = {5342-5374},
title = {Distributional equivalence and structure learning for bow-free acyclic path diagrams},
volume = {11},
journal = {Electronic Journal of Statistics},
doi = {10.1214/17-EJS1372}
}

@inproceedings{2024ma,
author = {Ma, Pingchuan and Ding, Rui and Fu, Qiang and Zhang, Jiaru and Wang, Shuai and Han, Shi and Zhang, Dongmei},
title = {Scalable Differentiable Causal Discovery in the Presence of Latent Confounders with Skeleton Posterior},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672031},
doi = {10.1145/3637528.3672031},
abstract = {Differentiable causal discovery has made significant advancements in the learning of directed acyclic graphs. However, its application to real-world datasets remains restricted due to the ubiquity of latent confounders and the requirement to learn maximal ancestral graphs (MAGs). To date, existing differentiable MAG learning algorithms have been limited to small datasets and failed to scale to larger ones (e.g., with more than 50 variables).The key insight in this paper is that the causal skeleton, which is the undirected version of the causal graph, has potential for improving accuracy and reducing the search space of the optimization procedure, thereby enhancing the performance of differentiable causal discovery. Therefore, we seek to address a two-fold challenge to harness the potential of the causal skeleton for differentiable causal discovery in the presence of latent confounders: (1) scalable and accurate estimation of skeleton and (2) universal integration of skeleton estimation with differentiable causal discovery.To this end, we propose SPOT (Skeleton Posterior-guided OpTimization), a two-phase framework that harnesses skeleton posterior for differentiable causal discovery in the presence of latent confounders. On the contrary to a "point-estimation", SPOT seeks to estimate the posterior distribution of skeletons given the dataset. It first formulates the posterior inference as an instance of amortized inference problem and concretizes it with a supervised causal learning (SCL)-enabled solution to estimate the skeleton posterior. To incorporate the skeleton posterior with differentiable causal discovery, SPOT then features a skeleton posterior-guided stochastic optimization procedure to guide the optimization of MAGs.Extensive experiments on various datasets show that SPOT substantially outperforms SOTA methods for MAG learning. SPOT also demonstrates its effectiveness in the accuracy of skeleton posterior estimation in comparison with non-parametric bootstrap-based, or more recently, variational inference-based methods. Finally, we observe that the adoption of skeleton posterior exhibits strong promise in various causal discovery tasks.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2141–2152},
numpages = {12},
keywords = {Bayesian network, causal discovery},
location = {Barcelona, Spain},
series = {KDD '24}
}

@misc{2021yu,
      title={DAGs with No Curl: An Efficient DAG Structure Learning Approach}, 
      author={Yue Yu and Tian Gao and Naiyu Yin and Qiang Ji},
      year={2021},
      eprint={2106.07197},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.07197}, 
}

@inproceedings{2008nickolls,
author = {Nickolls, John and Buck, Ian and Garland, Michael and Skadron, Kevin},
title = {Scalable parallel programming with CUDA},
year = {2008},
isbn = {9781450378451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1401132.1401152},
doi = {10.1145/1401132.1401152},
abstract = {Is CUDA the parallel programming model that application developers have been waiting for?},
booktitle = {ACM SIGGRAPH 2008 Classes},
articleno = {16},
numpages = {14},
location = {Los Angeles, California},
series = {SIGGRAPH '08}
}

@article{2023wen,
article_type = {journal},
title = {Applying causal discovery to single-cell analyses using CausalCell},
author = {Wen, Yujian and Huang, Jielong and Guo, Shuhui and Elyahu, Yehezqel and Monsonego, Alon and Zhang, Hai and Ding, Yanqing and Zhu, Hao},
editor = {Momeni, Babak and Akhmanova, Anna and Momeni, Babak},
volume = 12,
year = 2023,
month = {may},
pub_date = {2023-05-02},
pages = {e81464},
citation = {eLife 2023;12:e81464},
doi = {10.7554/eLife.81464},
url = {https://doi.org/10.7554/eLife.81464},
abstract = {Correlation between objects is prone to occur coincidentally, and exploring correlation or association in most situations does not answer scientific questions rich in causality. Causal discovery (also called causal inference) infers causal interactions between objects from observational data. Reported causal discovery methods and single-cell datasets make applying causal discovery to single cells a promising direction. However, evaluating and choosing causal discovery methods and developing and performing proper workflow remain challenges. We report the workflow and platform CausalCell (http://www.gaemons.net/causalcell/causalDiscovery/) for performing single-cell causal discovery. The workflow/platform is developed upon benchmarking four kinds of causal discovery methods and is examined by analyzing multiple single-cell RNA-sequencing (scRNA-seq) datasets. Our results suggest that different situations need different methods and the constraint-based PC algorithm with kernel-based conditional independence tests work best in most situations. Related issues are discussed and tips for best practices are given. Inferred causal interactions in single cells provide valuable clues for investigating molecular interactions and gene regulations, identifying critical diagnostic and therapeutic targets, and designing experimental and clinical interventions.},
keywords = {causal analysis, causal relationship, feature selection, network inference, scRNA-seq, single-cell analysis},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}

@inproceedings{2022ikram,
 author = {Ikram, Azam and Chakraborty, Sarthak and Mitra, Subrata and Saini, Shiv and Bagchi, Saurabh and Kocaoglu, Murat},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {31158--31170},
 publisher = {Curran Associates, Inc.},
 title = {Root Cause Analysis of Failures in Microservices through Causal Discovery},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/c9fcd02e6445c7dfbad6986abee53d0d-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inbook{2015imbens,
     place={Cambridge},
     title={CLASSICAL RANDOMIZED EXPERIMENTS},
     booktitle={Causal Inference for Statistics,
     Social,
     and Biomedical Sciences: An Introduction},
     publisher={Cambridge University Press},
     author={Imbens,
     Guido W. and Rubin,
     Donald B.},
     year={2015},
     pages={45–46}
}

