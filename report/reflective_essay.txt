1. Analysis of Strenths and Weaknesses
- 
2. Presentation of the possibilities for future work
    a. Alternatives to Proximal Policy Optimization
    The work done during the project and the extensive set of set of experiments performed, highlight the large sample in-efficiency of the Proximal Policy Optimization (PPO) algorithm. The contrast with the much better performance and faster runtime of the Covariance Matrix Adaptation - Evolutionary Strategy (CMA-ES) approach indicates that the issue lies with the PPO algorithm rather than with the general framework. Thus, it would be instructive to evaluate the performance of other more sample efficient deep reinforcement learning based algorithms on this problem. The primary reason for using deep RL is that, as demonstrated in [1], they can be effective in really high dimensional spaces. While the work done in the thesis only looks at graphs that have at-most 30 nodes, the authors of [1], for the comparatively simpler problem of Directed Acyclic Graph (DAG) discovery, demonstrate the effectiveness of PPO even in searching through a 20,000 dimensional space (for 200 node graphs). The main limitation in translating that performance to Acyclic Directed Mixed Graph (ADMG) search is that the computation of the BIC score is much more expensive. Thus, a more sample efficient algorithm than PPO can make better use of each BIC score evaluation.

    The main reason why the PPO algorithm is sample in-efficient is its on-policy nature. This means that it discard previously observed samples after a single update epoch. Thus, off policy algorithms, which cache previously observed samples for later re-use, might be an effective avenue to explore. The Soft Actor Critic (SAC) algorithm is the most prominent Deep Reinforcement Learning off-policy counterpart of the PPO algorithm.

    b. More Efficient BIC computation through RICF decomposition
    The log-likelihood for a DAG can be factorized into independent terms for each node conditioned on its parents. This factorization allows the authors of [1] to cache the partial sums required for computating the BIC score with the node and parents combination acting as the key into the cache. The allows for a constant time update per node modification. The log-likelihood term for the bow-free ADMGs does not permit the same per-node factorization, drastically increasing the time complexity of the BIC computation. The Residual Iterative Fitting (RICF) algorithm, which is used to compute the BIC scores for Linear Gaussian bow-free Acyclic Directed Mixed Graphs, is invoked 10's of thousands of times, every time that we want to find the candidate ground truth graph for a given dataset. Its time complexity is cubic in the number of nodes. Thus, any improvement to the RICF algorithm is likely to a have a reasonably large impact on the runtime and scalability of the framework proposed in the thesis.
    
    Although there is no per-node decomposition of the log-likelihood score, it does however, permits a decomposition based on the set of bidirected edge connected components (called districts) in the graph. All the nodes in each district are connected by bidirected paths and there are no bidirected edges between districts. Using this decomposition, we can achieve a time complexity for the RICF algorithm that is cubic in the sizes of the districts. This can be especially impactful for sparse graphs with a large number of small districts.

3. Work that you would have executed if you had more time
    a. Much longer and more comprehensive test suites
    Each run of PPO-based Relcadilac, for 10-node, degree 4, 2000 sample graphs would take around 30 minutes to run using the hyperparamers mentioned in the report. This was when using 80,000 BIC function evaluation or total timesteps as the threshold for termination. Assuming that this 30 minute runtime does not change with variation in graph parameters like number of nodes or sample size (which is definitely not the case), the production of the graphs in the paper, only for the Relcadilac algorithm, required over 100 hours (4 varying graph attributes, 5 values per attribute, 5 runs per attribute value, and 2 graph classes). The authors of [1] run their PPO algorithm on the simpler problem of DAGs for 1,280,000 total timesteps, which is a 16 fold increase. Thus, I would have run all the algorithms (even the CMA-ES algorithm) for longer (although not 16 times longer) to get a better idea of their capabilities at convergence.

    As mentioned in the paper, although the Sachs dataset is quite widely used in the causal discovery literature, there is still some debate concerning its ground truth graph. I came to know this fact regarding the Sachs dataset quite late in the thesis work, or I would have substituted it for a better understood real world dataset. I had found the Causal Chambers real-world dataset, which derives its data from a pair of well-understood computer controlled devices that allow them to obtain a large set of observational and interventional datasets with known ground truth causal graphs. In the event of greater time availability I would have liked to explore the performance of the proposed algorithms on this dataset.

    While the algorithms were evaluated on varying graph densities (in terms of average degrees of the graphs), I would also have liked to evaluate the performance of the algorithms on large sparse graphs (40 or 50 node graphs with average degree 2). I would also be interested in evaluating the performance of the algorithms in the case of model mis-specifications. How do the algorithms handle the case where the noise is sampled from the Uniform distribution or the Laplace distribution rather than the normal distribution. Or if instead of violating the Gaussianity, I kept the Gaussian noise, but instead of linear functions, the data was sampled from a non-linear gaussian SCM. Potential non-linearities could be simple polynomials like quadratic or cubic functions, or more sophisticated non-linearities like a randomly initialized neural network. These experiments might be useful in testing the robustness of the proposed algorithm: is the algorithm more susceptible to non-linearities in the data or to non-gaussian errors?

    Another potential improvement to the test suite would be to include more algorithms to compare against. The set of algorithms compared against was limited due to the large amount of time required to test the current set of algorithms. Even the DCD algorithm required more than an hour on the 30-node graphs. Due to limitations of space in the report, some recent algorithms for causal discovery were not mentioned since they weren't directly relevant to the approach taken in the report. One such algorithm is the N-ADMG or Neural ADMG algorithm [2]. The authors establish that under conditions of non-linear additive noise SCMs, bow-free ADMGs, and observable and unobservable variable non-modulation, the ADMG is identifiable. They transform the ADMG into a DAG through "magnification" where they introduce a latent variable for each confounded edge, parameterize the non-linear functions using neural networks, use variational inference to approximate the posterior over the graphs and the latent variables, and use a differentiable constraint to enforce acyclicity, similar to the constraint used in DCD. As a point of comparison, this algorithm could be interesting in that it is a more general algorithm for non-linear confounding being compared to algorithms specifically designed for linear gaussian confounded data, like the one we propose.

4. Critical analysis of the relationship between theory and practical work produced
5. Awareness of the Legal, Social, Ethical and Sustainability Issues

References:
[1] B. Duong, H. Le, B. Huang, and T. Nguyen, "Reinforcement learning for causal discovery without acyclicity constraints," Transactions on Machine Learning Research, 2025. [Online]. Available: https://openreview.net/forum?id=sNzBi8rZTy

[2] M. Ashman, C. Ma, A. Hilmkil, J. Jennings, and C. Zhang, "Causal reasoning in the presence of latent confounders via neural ADMG learning," in The Eleventh International Conference on Learning Representations, 2023. [Online]. Available: https://openreview.net/forum?id=dcN0CaXQhT
