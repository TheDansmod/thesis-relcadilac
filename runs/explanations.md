1. Run 01 was 1 run for ancestral admgs sample sizes 500, 1000, 2000, 4000 - for relcadilac, dcd, gfci - these can't directly be used since there was no thresholding - but they can be used to compare the impact of thresholding
2. Run 02 will be for 4 runs for the same as point 1 - so that in total they make 5 runs - can use commit b4a60cfd21c12864070a8a93fb07e6bb39521382 as reference - these can't directly be used since there was no thresholding - but they can be used to compare the impact of thresholding
3. Run 03 will be for ancestral admgs varying the number of nodes [5, 10, 15, 20, 30] - for relcadilac, dcd, gfci - can use commit 80a3c11c7c8103f8b00cc6c740584b8 as reference - these can't directly be used since there was no thresholding - but they can be used to compare the impact of thresholding
4. Run 04 is not a separate run, I have just combined the data from point 1 and point 2 to make a 5 run set for ancestral admgs with sample sizes 500, 1000, 2000, 4000 for relcadilac, dcd, gfci - these can't directly be used since there was no thresholding - but they can be used to compare the impact of thresholding
5. For the above graphs can use commit 00d1e5877176df94dee36ac21da393549a270a7f as reference (for code and everything)
6. Run 05 is just a single test of relcadilac to see how long 7 node 3000 sample size data takes to run --- it takes 3.4 minutes
7. In Run 06 I am again doing a 5 node 500 sample size test to see how the rewards returned by relcadilac are handled --- the rewards for this converges - which was quite obvious since during the end 500 sample ones speed up quite a bit meaning the LRU cache is being hit more
8. In run 07 I am trying to properly test the impact of sample size on the bic score - and how it compares with the ground truth bic - does the difference between the ground truth bic and the predicted bic (perhaps percentage difference) decrease as the sample size increases. I am also capturing some data on the average rewards to see whether 16000 is sufficient or I need to increase it. Only relcadilac in the runs with sample sizes [500, 600, 700, 1000, 1500, 2000, 2500, 3000] each of them run 10 times - all of them with 7 nodes.
9. In run 08 I am running the bow free admg model on the sachs data set - without thresholding
10. In run 09 I am running the same test as run 01, but with thresholding applied - but this is only for relcadilac since I have added the thresholding, and want to recalculate its metrics. In order to do a comparision we would have to merge the data -- can use commit aa1a554e7a5e1d7cca458782e50e76937af04cee for code reference - there was a mistake conducting this test - the thresholding was applied incorrectly - rather than applying it to just the magnitude, the full value was compared
11. In run 10, I am running the same test as run 09, but with the bug in the code corrected - in the thresholding function in the utils.py file - but I am running the loop just twice rather than 5 times since 5 times takes too long - can use commit f437c4b0a18112e5f87aa61d12eaa11a9a9ec6a1 for code reference
12. In run 11, I am doing num nodes variation [5, 10, 15, 20, 30] with 2000 sample size - each run 5 times with thresholding - for relcadilac, dcd, gfci for bow-free graphs
13. In run 12 I am doing sample size variation [500, 1000, 2000, 4000] - each run 5 times with thresholding - for relcadilac, dcd, gfci for bow-free graphs - all 10 node graphs
14. In run 13, i am running an ancestral node 15, 2000 samples, 4000 steps_per_env, 4 degree run to see how long it takes and if the non-convergence issue is still present - only comparing dcd and relcadilac - the model converged - but still had a worse bic than dcd
15. In run 14 I am running an ancestral node 10, 4000 samples, 4000 steps_per_env, 4 degree run to see if the ground truth graph can be recovered or lower bic than the ground truth model can be obtained or if we can beat dcd on bic / shd / f1 score. we can beat dcd, but not obtain the lowest score.
16. in run 15 i am running an ancestral node 10, 4000 samples, 4000 steps_per_env, 4 degree run to see if it is possible to recover the true graph - and to see if it is possible to get a better bic than dcd.  - only relcadilac
17. In Run 16, I have provided the topo order to the model and the model must only find the edges. I wanted to see if the model performs better at this than before. The size and complexity of the search space is reduced. Everything else is default: 10 nodes, 4 degree, 2000 samples, 2000 steps_per_env, using thresholding - only relcadilac - this is incorrect and needs to be run again - I have just rerun it with the fix - I have run this again - and the topo order known method does perform better - but it is still not able to find the minimum bic graph - this is saved as ancestral_fraction_excess_bic_with_without_topo_order.png
18. In run 17, I have an alternative vec2admg function for bow-free graphs which I compare against my current formulation. The new method is called logits and my previous formulation is called hierarchical since it gives primacy to directed edges over undirected edges. I keep everything else default - 10 nodes, 4 degree, 2000 samples, 2000 steps_per_env, using thresholding, no topo order - only relcadilac - the logits formulation took double the time to run and gave results which were slightly worse than the hierarchical formulation (by 4 units on the BIC value)
19. In run 18 I am trying to see if my model is able to find the results for just a DAG rather than an ADMG, I am using linear gaussian data with equal variances since that way the DAG is identifiable. Currently it just seems to predict no edges. - I was able to get the ground truth DAG, but had to run for 20_000 steps_per_env and n_step = 1, n_env = 8, so total = 160,000. It took 2 mins to run which was incredibly fast. I will now try n_step = 16, as see if there is a difference in the runtime
20. In run 19 and 20 I am trying to figure out the impact of the n_steps variable. When n_steps = 16, I don't get the optimal BIC, but I do when n_steps = 1. n_steps determines how frequently policy updates happen. The policy will be updated after collection n_steps of data from each environment. It seems better to keep the n_steps to 1.
21. In run 21 I am checking the impact of n_envs = 16 to see how it performs. It seems since the buffer size that goes in for an update becomes larger, there is less stochasticity - and thus, for the same reason that n_steps = 1 > n_steps = 16, we have n_envs = 8 > n_envs = 16.
22. In run 22 I am trying to figure out if using n_steps = 1 and steps_per_env = 20_000 is sufficient to find the ground truth ADMG - at least for ancestral ADMG. But that is not the case - I got closer - but not able to find the actual ground truth ADMG. truth = 22,616.something and relcadilac BIC = 22,623.something - so only a difference of 7 points. It took 2 minutes 21 seconds to complete.
23. In run 23 I am continuing the experiment from run 22 - how many steps_per_env needed to get the ground truth ancestral ADMG - with this time using 40,000 = steps_per_env, n_step = 1 (still), n_envs = 8
24. In run 24 I am continuing the experiment from run 22 - how many steps_per_env needed to get the ground truth ancestral ADMG - with this time using 80_000 = steps_per_env, n_step = 1 (still), n_envs = 8 - It could not find the ground truth BIC even with this intensive search
25. In run 25, I tried to use entropy annealing to see if it might help me find the true min bic graph, but it also, only got to the same value that previous runs got. I will be deleting it and creating a new run 25 where I will also be capturing action values since I want to see what the magnitude of the action values is throughout the run. - the bic found was lower than the bic of the true graph. the length of the z vector rose nearly linearly to over 100 (which should not be possible since the graph is 10 node) and then plumetted nearly vertically to nearly 0 at around 20k steps and stayed there for the rest of the run. I don't entirely understand this behaviour. The most likely cause of the behaviour is that I was capturing the unclipped action values rather than the clipped ones. I am not sure why it plummetted to 0.
26. In run 26, I will be trying to restrict the range of the action space to -1, 1 since -10, 10 does not seem necessary
27. In run 27, I am doing the same as run 26, but have raised the initial entropy since I am still getting stuck just above the minimum for run 26, and I am only tracking clipped actions not the unclipped actions so perhaps I'll see a better graph. I just looked at the graph for action values and while the magnitude has been fixed (does not exceed 10), there is still a complete drop at 20k. I have set the value of cycle length for entropy at 20k. I think the drop is because of that. But not entirely sure how.
28. In run 28 I am still investigating the collapse of the action values length. I will be changing the entropy cycle length to be shorter and see if that has any impact. I will keep the same seed as run 27. Something quite weird seems to have happened where the lengths of the clipped action values that I was tracking seem to have become absurdly large despite the restriction to be between -1 and 1. They reached values of 10 pow 38. I have it captured in a plot in diagrams folder. There was no convergence, no nothing. The reason for this is that 10 pow 38 is close the max representable value in IEEE so I was likely plotting just junk. The reason for the collapse to 0 at 20,000 steps was that I had allocated full total_timesteps length for action values but the on_step function is only called once every 8 timesteps so only the first 20k out of 160k timesteps were filled - the rest were 0.
29. In run 29, I am trying to figure out what is going on with the action vectors. But this time I have also 
















30. In run 15 I am trying to figure out the impact of more steps_per_env (2000, 3000, 4000) on the excess bic value - how much the predicted bic is larger than the true bic - I am doing 3 runs per steps_per_env value. This is for 15 node, 4 degree, 2000 samples - this is only for dcd and relcadilac. This is for ancestral graphs.
